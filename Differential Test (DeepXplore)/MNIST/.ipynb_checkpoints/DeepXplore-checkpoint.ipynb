{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "usage: python gen_diff.py -h\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input\n",
    "from scipy.misc import imsave\n",
    "\n",
    "from Model1 import Model1\n",
    "from Model2 import Model2\n",
    "from Model3 import Model3\n",
    "from configs import bcolors\n",
    "from utils import *\n",
    "\n",
    "# read the parameter\n",
    "# argument parsing\n",
    "parser = argparse.ArgumentParser(description='Main function for difference-inducing input generation in MNIST dataset')\n",
    "parser.add_argument('transformation', help=\"realistic transformation type\", choices=['light', 'occl', 'blackout'])\n",
    "parser.add_argument('weight_diff', help=\"weight hyperparm to control differential behavior\", type=float)\n",
    "parser.add_argument('weight_nc', help=\"weight hyperparm to control neuron coverage\", type=float)\n",
    "parser.add_argument('step', help=\"step size of gradient descent\", type=float)\n",
    "parser.add_argument('seeds', help=\"number of seeds of input\", type=int)\n",
    "parser.add_argument('grad_iterations', help=\"number of iterations of gradient descent\", type=int)\n",
    "parser.add_argument('threshold', help=\"threshold for determining neuron activated\", type=float)\n",
    "parser.add_argument('-t', '--target_model', help=\"target model that we want it predicts differently\",\n",
    "                    choices=[0, 1, 2], default=0, type=int)\n",
    "parser.add_argument('-sp', '--start_point', help=\"occlusion upper left corner coordinate\", default=(0, 0), type=tuple)\n",
    "parser.add_argument('-occl_size', '--occlusion_size', help=\"occlusion size\", default=(10, 10), type=tuple)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# the data, shuffled and split between train and test sets\n",
    "(_, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "\n",
    "# define input tensor as a placeholder\n",
    "input_tensor = Input(shape=input_shape)\n",
    "\n",
    "# load multiple models sharing same input tensor\n",
    "model1 = Model1(input_tensor=input_tensor)\n",
    "model2 = Model2(input_tensor=input_tensor)\n",
    "model3 = Model3(input_tensor=input_tensor)\n",
    "\n",
    "# init coverage table\n",
    "model_layer_dict1, model_layer_dict2, model_layer_dict3 = init_coverage_tables(model1, model2, model3)\n",
    "\n",
    "# ==============================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start gen inputs\n",
    "for _ in xrange(args.seeds):\n",
    "    gen_img = np.expand_dims(random.choice(x_test), axis=0)\n",
    "    orig_img = gen_img.copy()\n",
    "    # first check if input already induces differences\n",
    "    label1, label2, label3 = np.argmax(model1.predict(gen_img)[0]), np.argmax(model2.predict(gen_img)[0]), np.argmax(\n",
    "        model3.predict(gen_img)[0])\n",
    "\n",
    "    if not label1 == label2 == label3:\n",
    "        print(bcolors.OKGREEN + 'input already causes different outputs: {}, {}, {}'.format(label1, label2,\n",
    "                                                                                            label3) + bcolors.ENDC)\n",
    "\n",
    "        update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
    "        update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
    "        update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
    "\n",
    "        print(bcolors.OKGREEN + 'covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
    "              % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
    "                 neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
    "                 neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n",
    "        averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
    "                       neuron_covered(model_layer_dict3)[0]) / float(\n",
    "            neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
    "            neuron_covered(model_layer_dict3)[\n",
    "                1])\n",
    "        print(bcolors.OKGREEN + 'averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n",
    "\n",
    "        gen_img_deprocessed = deprocess_image(gen_img)\n",
    "\n",
    "        # save the result to disk\n",
    "        imsave('./generated_inputs/' + 'already_differ_' + str(label1) + '_' + str(\n",
    "            label2) + '_' + str(label3) + '.png', gen_img_deprocessed)\n",
    "        continue\n",
    "\n",
    "    # if all label agrees\n",
    "    orig_label = label1\n",
    "    layer_name1, index1 = neuron_to_cover(model_layer_dict1)\n",
    "    layer_name2, index2 = neuron_to_cover(model_layer_dict2)\n",
    "    layer_name3, index3 = neuron_to_cover(model_layer_dict3)\n",
    "\n",
    "    # construct joint loss function\n",
    "    if args.target_model == 0:\n",
    "        loss1 = -args.weight_diff * K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
    "        loss2 = K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
    "        loss3 = K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
    "    elif args.target_model == 1:\n",
    "        loss1 = K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
    "        loss2 = -args.weight_diff * K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
    "        loss3 = K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
    "    elif args.target_model == 2:\n",
    "        loss1 = K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
    "        loss2 = K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
    "        loss3 = -args.weight_diff * K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
    "    loss1_neuron = K.mean(model1.get_layer(layer_name1).output[..., index1])\n",
    "    loss2_neuron = K.mean(model2.get_layer(layer_name2).output[..., index2])\n",
    "    loss3_neuron = K.mean(model3.get_layer(layer_name3).output[..., index3])\n",
    "    layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron)\n",
    "\n",
    "    # for adversarial image generation\n",
    "    final_loss = K.mean(layer_output)\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = normalize(K.gradients(final_loss, input_tensor)[0])\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_tensor], [loss1, loss2, loss3, loss1_neuron, loss2_neuron, loss3_neuron, grads])\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for iters in xrange(args.grad_iterations):\n",
    "        loss_value1, loss_value2, loss_value3, loss_neuron1, loss_neuron2, loss_neuron3, grads_value = iterate(\n",
    "            [gen_img])\n",
    "        if args.transformation == 'light':\n",
    "            grads_value = constraint_light(grads_value)  # constraint the gradients value\n",
    "        elif args.transformation == 'occl':\n",
    "            grads_value = constraint_occl(grads_value, args.start_point,\n",
    "                                          args.occlusion_size)  # constraint the gradients value\n",
    "        elif args.transformation == 'blackout':\n",
    "            grads_value = constraint_black(grads_value)  # constraint the gradients value\n",
    "\n",
    "        gen_img += grads_value * args.step\n",
    "        predictions1 = np.argmax(model1.predict(gen_img)[0])\n",
    "        predictions2 = np.argmax(model2.predict(gen_img)[0])\n",
    "        predictions3 = np.argmax(model3.predict(gen_img)[0])\n",
    "\n",
    "        if not predictions1 == predictions2 == predictions3:\n",
    "            update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
    "            update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
    "            update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
    "\n",
    "            print(bcolors.OKGREEN + 'covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
    "                  % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
    "                     neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
    "                     neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n",
    "            averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
    "                           neuron_covered(model_layer_dict3)[0]) / float(\n",
    "                neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
    "                neuron_covered(model_layer_dict3)[\n",
    "                    1])\n",
    "            print(bcolors.OKGREEN + 'averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n",
    "\n",
    "            gen_img_deprocessed = deprocess_image(gen_img)\n",
    "            orig_img_deprocessed = deprocess_image(orig_img)\n",
    "\n",
    "            # save the result to disk\n",
    "            imsave('./generated_inputs/' + args.transformation + '_' + str(predictions1) + '_' + str(\n",
    "                predictions2) + '_' + str(predictions3) + '.png',\n",
    "                   gen_img_deprocessed)\n",
    "            imsave('./generated_inputs/' + args.transformation + '_' + str(predictions1) + '_' + str(\n",
    "                predictions2) + '_' + str(predictions3) + '_orig.png',\n",
    "                   orig_img_deprocessed)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
