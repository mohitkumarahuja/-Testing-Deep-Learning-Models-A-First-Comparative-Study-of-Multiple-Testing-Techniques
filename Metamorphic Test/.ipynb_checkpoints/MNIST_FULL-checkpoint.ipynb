{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Dataset Training of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::#\n",
    "# Mohit Kumar Ahuja                                                             #\n",
    "# PhD Student                                                                   #\n",
    "# Simula Research Laboratory                                                    #\n",
    "# mohit@simula.no                                                               #\n",
    "# File: Full Dataset Training of MNIST                                  #\n",
    "#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::#\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import keras\n",
    "#from Functions_Regression_Testing import*\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.datasets import mnist\n",
    "#from Functions_Regression_Testing import*\n",
    "from keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "now = datetime.datetime.now\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "    \n",
    "################################################################################\n",
    "########################## SOME FUNCTIONS ######################################\n",
    "################################################################################\n",
    "def shuffle_Data_2D(X, Y):\n",
    "\n",
    "    print('shape before shuffling:', X.shape)\n",
    "    # Shuffling all the Images\n",
    "    m = X.shape[1]      # number of training examples \n",
    "    # Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:,permutation]\n",
    "    shuffled_Y = Y[permutation]\n",
    "    print('shape after shuffling:', shuffled_X.shape)\n",
    "\n",
    "    return shuffled_X, shuffled_Y\n",
    "\n",
    "class TimeTestAccHistory(keras.callbacks.Callback):\n",
    "    def __init__(self, x_test_call, y_test, y_test_call):\n",
    "        super(TimeTestAccHistory, self).__init__()\n",
    "        self.x_test_call = x_test_call\n",
    "        self.y_test = y_test\n",
    "        self.y_test_call = y_test_call\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "        self.test_acc = []\n",
    "        self.avg_conf = []\n",
    "        self.max_miscl_num = []\n",
    "        self.conf_class_median = []\n",
    "        self.std_conf = []\n",
    "        self.most_conf_class_1 = []\n",
    "        self.most_conf_class_2 = []\n",
    "        self.sum_of_confused_classes = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.start)        \n",
    "        test_accuracy = self.model.evaluate(self.x_test_call, self.y_test_call)\n",
    "        self.test_acc.append(test_accuracy[1])\n",
    "        \n",
    "        rounded_pred_call = self.model.predict_classes(self.x_test_call, batch_size = 32, verbose = 0)\n",
    "        cm = confusion_matrix(rounded_pred_call, self.y_test)\n",
    "        np.fill_diagonal(cm, 0)\n",
    "        Total_misclassified_images = cm.sum()\n",
    "        self.sum_of_confused_classes.append(Total_misclassified_images)\n",
    "        \n",
    "        percentage = self.y_test_call.shape[1] / 10\n",
    "        remaining = (self.y_test_call.shape[1] - np.int(percentage))*10\n",
    "        Average_Confusion = Total_misclassified_images/remaining\n",
    "        self.avg_conf.append(Average_Confusion)\n",
    "        \n",
    "        maximum_misclassified_images = cm.max()\n",
    "        self.max_miscl_num.append(maximum_misclassified_images)\n",
    "        \n",
    "        confused_classes=[]\n",
    "        for i in range(len(cm)):\n",
    "            for j in range (len(cm)):\n",
    "                if i != j and cm[i,j] >= maximum_misclassified_images:\n",
    "                    #print('Class ' + str(i) + ' and Class ' + str(j) + ' have high confusion rate')\n",
    "                    confused_classes.append(i)\n",
    "                    confused_classes.append(j)\n",
    "                    \n",
    "        self.most_conf_class_1.append(confused_classes[0])\n",
    "        self.most_conf_class_2.append(confused_classes[1])\n",
    "        \n",
    "        con_median = np.median(cm)\n",
    "        self.conf_class_median.append(con_median)\n",
    "        \n",
    "        std_conf = np.std(cm)\n",
    "        self.std_conf.append(std_conf)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def train_model_mnist_call(model, train, val, test, num_classes, input_shape, batch_size, epochs, lr, callbacks, time_history, mode, hist_csv_file):\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    Dev_X = val[0].reshape((val[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    Dev_X = Dev_X.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    #print('x_train shape:', x_train.shape)\n",
    "    #print('Dev_X Shape:', Dev_X.shape)\n",
    "    #print(\"X_test Shape:\", x_test.shape)\n",
    "    #print(x_train.shape[0], 'train samples')\n",
    "    #print(Dev_X.shape[0], 'validation samples')\n",
    "    #print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    Dev_Y = keras.utils.to_categorical(val[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(Dev_X, Dev_Y), callbacks = callbacks)\n",
    "    history.history['time'] = time_history.times\n",
    "    history.history['test_acc'] = time_history.test_acc\n",
    "    history.history['avg_conf'] = time_history.avg_conf\n",
    "    history.history['max_miscl_num'] = time_history.max_miscl_num\n",
    "    history.history['conf_class_median'] = time_history.conf_class_median\n",
    "    history.history['std_conf'] = time_history.std_conf\n",
    "    history.history['most_conf_class_1'] = time_history.most_conf_class_1\n",
    "    history.history['most_conf_class_2'] = time_history.most_conf_class_2\n",
    "    history.history['sum_of_confused_classes'] = time_history.sum_of_confused_classes\n",
    "    \n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    with open(hist_csv_file, mode=mode, newline = '\\n') as f:\n",
    "        #print(hist_df.head())\n",
    "        hist_df.to_csv(f, index= False, header=mode=='w')\n",
    "    \n",
    "    print(\"*******************************************\")\n",
    "    print('Training time: %s' % (now() - t))\n",
    "    #print('x_test shape:', x_test.shape)\n",
    "    #print('y_test shape:', y_test.shape)\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"*******************************************\")\n",
    "    #print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print(\"*******************************************\")\n",
    "\n",
    "\n",
    "    \n",
    "################################################################################\n",
    "#################################  CODE  #######################################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import keras\n",
    "#from Functions_Regression_Testing import*\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.datasets import mnist\n",
    "#from Functions_Regression_Testing import*\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "now = datetime.datetime.now\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "    \n",
    "start = time.time()\n",
    "################################################################################\n",
    "########################## SOME FUNCTIONS ######################################\n",
    "################################################################################\n",
    "def shuffle_Data_2D(X, Y):\n",
    "\n",
    "    print('shape before shuffling:', X.shape)\n",
    "    # Shuffling all the Images\n",
    "    m = X.shape[1]      # number of training examples \n",
    "    # Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:,permutation]\n",
    "    shuffled_Y = Y[permutation]\n",
    "    print('shape after shuffling:', shuffled_X.shape)\n",
    "\n",
    "    return shuffled_X, shuffled_Y\n",
    "\n",
    "class TimeTestAccHistory(keras.callbacks.Callback):\n",
    "    def __init__(self, x_test_call, y_test, y_test_call):\n",
    "        super(TimeTestAccHistory, self).__init__()\n",
    "        self.x_test_call = x_test_call\n",
    "        self.y_test = y_test\n",
    "        self.y_test_call = y_test_call\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "        self.test_acc = []\n",
    "        self.avg_conf = []\n",
    "        self.max_miscl_num = []\n",
    "        self.conf_class_median = []\n",
    "        self.std_conf = []\n",
    "        self.most_conf_class_1 = []\n",
    "        self.most_conf_class_2 = []\n",
    "        self.sum_of_confused_classes = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.start)        \n",
    "        test_accuracy = self.model.evaluate(self.x_test_call, self.y_test_call)\n",
    "        self.test_acc.append(test_accuracy[1])\n",
    "        \n",
    "        rounded_pred_call = self.model.predict_classes(self.x_test_call, batch_size = 32, verbose = 0)\n",
    "        cm = confusion_matrix(rounded_pred_call, self.y_test)\n",
    "        np.fill_diagonal(cm, 0)\n",
    "        Total_misclassified_images = cm.sum()\n",
    "        self.sum_of_confused_classes.append(Total_misclassified_images)\n",
    "        \n",
    "        percentage = self.y_test_call.shape[1] / 10\n",
    "        remaining = (self.y_test_call.shape[1] - np.int(percentage))*10\n",
    "        Average_Confusion = Total_misclassified_images/remaining\n",
    "        self.avg_conf.append(Average_Confusion)\n",
    "        \n",
    "        maximum_misclassified_images = cm.max()\n",
    "        self.max_miscl_num.append(maximum_misclassified_images)\n",
    "        \n",
    "        confused_classes=[]\n",
    "        for i in range(len(cm)):\n",
    "            for j in range (len(cm)):\n",
    "                if i != j and cm[i,j] >= maximum_misclassified_images:\n",
    "                    #print('Class ' + str(i) + ' and Class ' + str(j) + ' have high confusion rate')\n",
    "                    confused_classes.append(i)\n",
    "                    confused_classes.append(j)\n",
    "                    \n",
    "        self.most_conf_class_1.append(confused_classes[0])\n",
    "        self.most_conf_class_2.append(confused_classes[1])\n",
    "        \n",
    "        con_median = np.median(cm)\n",
    "        self.conf_class_median.append(con_median)\n",
    "        \n",
    "        std_conf = np.std(cm)\n",
    "        self.std_conf.append(std_conf)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def train_model_mnist_call(model, train, val, test, num_classes, input_shape, batch_size, epochs, lr, callbacks, time_history, mode, hist_csv_file):\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    Dev_X = val[0].reshape((val[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    Dev_X = Dev_X.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    #print('x_train shape:', x_train.shape)\n",
    "    #print('Dev_X Shape:', Dev_X.shape)\n",
    "    #print(\"X_test Shape:\", x_test.shape)\n",
    "    #print(x_train.shape[0], 'train samples')\n",
    "    #print(Dev_X.shape[0], 'validation samples')\n",
    "    #print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    Dev_Y = keras.utils.to_categorical(val[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(Dev_X, Dev_Y), callbacks = callbacks)\n",
    "    history.history['time'] = time_history.times\n",
    "    history.history['test_acc'] = time_history.test_acc\n",
    "    history.history['avg_conf'] = time_history.avg_conf\n",
    "    history.history['max_miscl_num'] = time_history.max_miscl_num\n",
    "    history.history['conf_class_median'] = time_history.conf_class_median\n",
    "    history.history['std_conf'] = time_history.std_conf\n",
    "    history.history['most_conf_class_1'] = time_history.most_conf_class_1\n",
    "    history.history['most_conf_class_2'] = time_history.most_conf_class_2\n",
    "    history.history['sum_of_confused_classes'] = time_history.sum_of_confused_classes\n",
    "    \n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    with open(hist_csv_file, mode=mode, newline = '\\n') as f:\n",
    "        #print(hist_df.head())\n",
    "        hist_df.to_csv(f, index= False, header=mode=='w')\n",
    "    \n",
    "    print(\"*******************************************\")\n",
    "    print('Training time: %s' % (now() - t))\n",
    "    #print('x_test shape:', x_test.shape)\n",
    "    #print('y_test shape:', y_test.shape)\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"*******************************************\")\n",
    "    #print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print(\"*******************************************\")\n",
    "\n",
    "  \n",
    "################################################################################\n",
    "#################################  CODE  #######################################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "hist_csv_file = 'history_MNIST_FULL_TRAINING.csv'\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = 2\n",
    "# convolution kernel size\n",
    "kernel_size = 3\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    \n",
    "#######################################################################\n",
    "# MNIST Load data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#######################################################################\n",
    "# Reshaping it to (60000,784)\n",
    "#X_test_flatten = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n",
    "#X_test_flatten = np.transpose(X_test_flatten)\n",
    "# Shuffling Data\n",
    "#St_X, St_Y = shuffle_Data_2D(X_test_flatten, y_train)\n",
    "\n",
    "#x_test=np.transpose(St_X)\n",
    "#x_test=x_test.reshape((x_test.shape[0], 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# define number of images to show\n",
    "num_row = 2\n",
    "num_col = 8\n",
    "num= num_row*num_col\n",
    "\n",
    "# get images\n",
    "images = x_test[0:num]\n",
    "labels = y_test[0:num]\n",
    "\n",
    "# plot images\n",
    "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for i in range(num):\n",
    "    ax = axes[i//num_col, i%num_col]\n",
    "    ax.imshow(images[i], cmap='gray_r')\n",
    "    ax.set_title('Label: {}'.format(labels[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# specify the maximum rotation_range angle\n",
    "rotation_range_val = 90\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=rotation_range_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(x_test.reshape(x_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# define number of rows & columns\n",
    "num_row = 2\n",
    "num_col = 8\n",
    "num= num_row*num_col\n",
    "\n",
    "# plot before\n",
    "print('BEFORE:\\n')\n",
    "# plot images\n",
    "fig1, axes1 = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for i in range(num):\n",
    "    ax = axes1[i//num_col, i%num_col]\n",
    "    ax.imshow(x_test[i], cmap='gray_r')\n",
    "    ax.set_title('Label: {}'.format(y_test[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot after\n",
    "print('AFTER:\\n')\n",
    "fig2, axes2 = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for X, Y in datagen.flow(x_test.reshape(x_test.shape[0], 28, 28, 1), \n",
    "                         y_test.reshape(y_test.shape[0], 1), \n",
    "                         batch_size=num, \n",
    "                         shuffle=False):\n",
    "    for i in range(0, num):\n",
    "        ax = axes2[i//num_col, i%num_col]\n",
    "        ax.imshow(X[i].reshape(28,28), cmap='gray_r')\n",
    "        ax.set_title('Label: {}'.format(int(Y[i])))\n",
    "    break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width Shift and Height Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0f378e572f6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# create the class object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdatagen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth_shift_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth_shift_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight_shift_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight_shift_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# fit the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "# specify the width and height shift arguments\n",
    "width_shift_val = 0.5\n",
    "height_shift_val = 0.5\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(width_shift_range=width_shift_val, height_shift_range=height_shift_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(x_train.reshape(x_train.shape[0], 28, 28, 1))\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "\n",
    "# define number of rows & columns\n",
    "num_row = 2\n",
    "num_col = 8\n",
    "num= num_row*num_col\n",
    "\n",
    "# plot before\n",
    "print('BEFORE:\\n')\n",
    "# plot images\n",
    "fig1, axes1 = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for i in range(num):\n",
    "    ax = axes1[i//num_col, i%num_col]\n",
    "    ax.imshow(x_train[i], cmap='gray_r')\n",
    "    ax.set_title('Label: {}'.format(y_train[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot after\n",
    "print('AFTER:\\n')\n",
    "fig2, axes2 = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for X, Y in datagen.flow(x_train.reshape(x_train.shape[0], 28, 28, 1), \n",
    "                         y_train.reshape(y_train.shape[0], 1), \n",
    "                         batch_size=num, \n",
    "                         shuffle=False):\n",
    "    for i in range(0, num):\n",
    "        ax = axes2[i//num_col, i%num_col]\n",
    "        ax.imshow(X[i].reshape(28,28), cmap='gray_r')\n",
    "        ax.set_title('Label: {}'.format(int(Y[i])))\n",
    "    break\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"x_test shape:\", x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shear"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# specify the shear argument\n",
    "shear_range_val=45\n",
    "\n",
    "# import relevant library\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(shear_range=shear_range_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(X_train.reshape(X_train.shape[0], 28, 28, 1))\n",
    "\n",
    "# define number of rows & columns\n",
    "num_row = 2\n",
    "num_col = 8\n",
    "num= num_row*num_col\n",
    "\n",
    "# plot before\n",
    "print('BEFORE:\\n')\n",
    "# plot images\n",
    "fig1, axes1 = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for i in range(num):\n",
    "    ax = axes1[i//num_col, i%num_col]\n",
    "    ax.imshow(X_train[i], cmap='gray_r')\n",
    "    ax.set_title('Label: {}'.format(Y_train[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot after\n",
    "print('AFTER:\\n')\n",
    "fig2, axes2 = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for X, Y in datagen.flow(X_train.reshape(X_train.shape[0], 28, 28, 1), \n",
    "                         Y_train.reshape(Y_train.shape[0], 1), \n",
    "                         batch_size=num, \n",
    "                         shuffle=False):\n",
    "    for i in range(0, num):\n",
    "        ax = axes2[i//num_col, i%num_col]\n",
    "        ax.imshow(X[i].reshape(28,28), cmap='gray_r')\n",
    "        ax.set_title('Label: {}'.format(int(Y[i])))\n",
    "    break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# specify the zoom argument\n",
    "zoom_range_val=[0.5,1.5]\n",
    "\n",
    "# import relevant library\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(zoom_range=zoom_range_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(X_train.reshape(X_train.shape[0], 28, 28, 1))\n",
    "\n",
    "# define number of rows & columns\n",
    "num_row = 2\n",
    "num_col = 8\n",
    "num= num_row*num_col\n",
    "\n",
    "# plot before\n",
    "print('BEFORE:\\n')\n",
    "# plot images\n",
    "fig1, axes1 = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for i in range(num):\n",
    "    ax = axes1[i//num_col, i%num_col]\n",
    "    ax.imshow(X_train[i], cmap='gray_r')\n",
    "    ax.set_title('Label: {}'.format(Y_train[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot after\n",
    "print('AFTER:\\n')\n",
    "fig2, axes2 = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for X, Y in datagen.flow(X_train.reshape(X_train.shape[0], 28, 28, 1), \n",
    "                         Y_train.reshape(Y_train.shape[0], 1), \n",
    "                         batch_size=num, \n",
    "                         shuffle=False):\n",
    "    for i in range(0, num):\n",
    "        ax = axes2[i//num_col, i%num_col]\n",
    "        ax.imshow(X[i].reshape(28,28), cmap='gray_r')\n",
    "        ax.set_title('Label: {}'.format(int(Y[i])))\n",
    "    break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'MNIST_FULL_%s_model.{epoch:03d}.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "input_shape = (x_test.shape[1], x_test.shape[2], 1)\n",
    "x_test_call = x_test.reshape((x_test.shape[0],) + input_shape)\n",
    "print(\"X_test shape = \", x_test_call.shape)\n",
    "y_test_call = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(\"Y_test shape = \", y_test.shape)\n",
    "print(\"Y_test_call shape = \", y_test_call.shape)\n",
    "\n",
    "time_history = TimeTestAccHistory(x_test_call, y_test, y_test_call)\n",
    "callbacks = [checkpoint, time_history]\n",
    "\n",
    "#######################################################################\n",
    "# Reshaping it to (60000,784)\n",
    "X_train_flatten = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "X_train_flatten = np.transpose(X_train_flatten)\n",
    "\n",
    "# Shuffling Data\n",
    "S_X, S_Y = shuffle_Data_2D(X_train_flatten, y_train)\n",
    "\n",
    "# Creating a train set from the training data\n",
    "x_train = S_X[:,0:40000]\n",
    "y_train = S_Y[0:40000]\n",
    "\n",
    "# Creating a Validation set for training\n",
    "Dev_X = S_X[:,40000:]\n",
    "Dev_Y = S_Y[40000:]\n",
    "\n",
    "x_train=np.transpose(x_train)\n",
    "Dev_X=np.transpose(Dev_X)\n",
    "x_train=x_train.reshape((x_train.shape[0], 28, 28))\n",
    "Dev_X=Dev_X.reshape((Dev_X.shape[0], 28, 28))\n",
    "\n",
    "##########################################################################\n",
    "# define two groups of layers: feature (convolutions) and classification (dense)\n",
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_test shape = \", x_test.shape)\n",
    "print(\"y_test shape = \", y_test.shape)\n",
    "print(\"x_train shape = \", x_train.shape)\n",
    "print(\"y_train shape = \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TRAINING\n",
    "############################################################################\n",
    "# create complete model\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "# train model\n",
    "train_model_mnist_call(model,(x_train, y_train),(Dev_X, Dev_Y), (x_test, y_test), \n",
    "                  num_classes, input_shape, batch_size, epochs=epochs, lr=0.001, \n",
    "                  callbacks=callbacks, time_history = time_history, mode='w', \n",
    "                  hist_csv_file = hist_csv_file)\n",
    "\n",
    "############################################################################\n",
    "print(\"Training FINISHED\")\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(hist_csv_file)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \"Accuracy\"\n",
    "plt.plot(data['acc'])\n",
    "plt.plot(data['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Loss\"\n",
    "plt.plot(data['loss'])\n",
    "plt.plot(data['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'])\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \"Average Confustion\"\n",
    "plt.plot(data['avg_conf'])\n",
    "plt.plot(data['std_conf'])\n",
    "plt.title('Confusion')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Avg Conf', 'Std Conf'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   \"sum_of_confused_classes\"\n",
    "plt.plot(data['sum_of_confused_classes'])\n",
    "plt.title('Sum of Confused Classes')\n",
    "plt.ylabel('Sum')\n",
    "plt.xlabel('epoch')\n",
    "#plt.legend(['Avg Conf', 'Std Conf'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   \"Max Misclassified\"\n",
    "plt.plot(data['max_miscl_num'])\n",
    "plt.title('Maximum Misclassified Number')\n",
    "plt.ylabel('Maximum Misclassified Number')\n",
    "plt.xlabel('epoch')\n",
    "#plt.legend(['Avg Conf', 'Std Conf'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
