{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "import os\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from math import ceil\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# Model configuration\n",
    "img_width, img_height = 28, 28\n",
    "batch_size = 250\n",
    "no_epochs = 20\n",
    "no_classes = 10\n",
    "validation_split = 0.2\n",
    "verbosity = 1\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "(input_train, target_train), (input_test, target_test) = mnist.load_data()\n",
    "\n",
    "# Reshape data\n",
    "input_train = input_train.reshape(input_train.shape[0], img_width, img_height, 1)\n",
    "input_test = input_test.reshape(input_test.shape[0], img_width, img_height, 1)\n",
    "input_shape = (img_width, img_height, 1)\n",
    "    \n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(no_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width and Height Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.3210 - acc: 0.9039\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0845 - acc: 0.9741\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0609 - acc: 0.9817\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0465 - acc: 0.9849\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0421 - acc: 0.9865\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0336 - acc: 0.9898\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0316 - acc: 0.9899\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0277 - acc: 0.9914\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0244 - acc: 0.9921\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0210 - acc: 0.9929\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0190 - acc: 0.9939\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0167 - acc: 0.9945\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0152 - acc: 0.9948\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0164 - acc: 0.9945\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0127 - acc: 0.9959\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0126 - acc: 0.9959\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0114 - acc: 0.9962\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0116 - acc: 0.9961\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0102 - acc: 0.9966\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0098 - acc: 0.9966\n",
      "Test loss: 0.025933824475703294 / Test accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "# specify the width and height shift arguments\n",
    "width_shift_val = 0.0\n",
    "height_shift_val = 0.0\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(width_shift_range=width_shift_val, height_shift_range=height_shift_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(input_train.reshape(input_train.shape[0], 28, 28, 1))\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "model.fit(datagen.flow(input_train, target_train, batch_size=batch_size),\n",
    "          epochs=no_epochs,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split)\n",
    "\n",
    "# Generate generalization metrics\n",
    "score = model.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.5439 - acc: 0.8273\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.1887 - acc: 0.9407\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.1373 - acc: 0.9564\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.1139 - acc: 0.9651\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0965 - acc: 0.9696\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0873 - acc: 0.9725\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0796 - acc: 0.9751\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0722 - acc: 0.9777\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0695 - acc: 0.9789\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0639 - acc: 0.9798\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0611 - acc: 0.9814\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0578 - acc: 0.9820\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0559 - acc: 0.9826\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0541 - acc: 0.9827\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0518 - acc: 0.9833\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0508 - acc: 0.9841\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0474 - acc: 0.9851\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0449 - acc: 0.9859\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0447 - acc: 0.9858\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0446 - acc: 0.9860\n",
      "Test loss: 0.0306446118159889 / Test accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "# specify the maximum rotation_range angle\n",
    "rotation_range_val = 60\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(rotation_range=rotation_range_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(input_train.reshape(input_train.shape[0], 28, 28, 1))\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "model.fit(datagen.flow(input_train, target_train, batch_size=batch_size),\n",
    "          epochs=no_epochs,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split)\n",
    "\n",
    "# Generate generalization metrics\n",
    "score = model.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.4631 - acc: 0.8547\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.1530 - acc: 0.9532\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.1123 - acc: 0.9639\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0907 - acc: 0.9711\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0781 - acc: 0.9752\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0686 - acc: 0.9786\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0594 - acc: 0.9815\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0574 - acc: 0.9814\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0524 - acc: 0.9834\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0489 - acc: 0.9847\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0465 - acc: 0.9847\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0438 - acc: 0.9860\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0400 - acc: 0.9872\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0403 - acc: 0.9871\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0365 - acc: 0.9886\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0348 - acc: 0.9892\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0336 - acc: 0.9889\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0322 - acc: 0.9898\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0314 - acc: 0.9899\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0312 - acc: 0.9901\n",
      "Test loss: 0.02260797252385528 / Test accuracy: 0.9923\n"
     ]
    }
   ],
   "source": [
    "# specify the shear argument\n",
    "shear_range_val=45\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(shear_range=shear_range_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(input_train.reshape(input_train.shape[0], 28, 28, 1))\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "model.fit(datagen.flow(input_train, target_train, batch_size=batch_size),\n",
    "          epochs=no_epochs,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split)\n",
    "\n",
    "# Generate generalization metrics\n",
    "score = model.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.5073 - acc: 0.8426\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.1711 - acc: 0.9480\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.1284 - acc: 0.9603\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.1049 - acc: 0.9671\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0910 - acc: 0.9720\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0820 - acc: 0.9740\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0765 - acc: 0.9766\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0683 - acc: 0.9779\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0677 - acc: 0.9789\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0615 - acc: 0.9809\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0596 - acc: 0.9807\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0572 - acc: 0.9820\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0537 - acc: 0.9832\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0497 - acc: 0.9841\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0515 - acc: 0.9839\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0494 - acc: 0.9840\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0465 - acc: 0.9858\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0451 - acc: 0.9858\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0432 - acc: 0.9860\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0436 - acc: 0.9862\n",
      "Test loss: 0.022944946550960594 / Test accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "# specify the zoom argument\n",
    "zoom_range_val=[0.5,1.5]\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(zoom_range=zoom_range_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(input_train.reshape(input_train.shape[0], 28, 28, 1))\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "model.fit(datagen.flow(input_train, target_train, batch_size=batch_size),\n",
    "          epochs=no_epochs,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split)\n",
    "\n",
    "# Generate generalization metrics\n",
    "score = model.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate + W&H Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 0.6743 - acc: 0.7837\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2371 - acc: 0.9267\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1685 - acc: 0.9476\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1354 - acc: 0.9580\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1161 - acc: 0.9638\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1041 - acc: 0.9672\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0946 - acc: 0.9705\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0865 - acc: 0.9725\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0804 - acc: 0.9740\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0758 - acc: 0.9761\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0735 - acc: 0.9770\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0711 - acc: 0.9776\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0673 - acc: 0.9790\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0628 - acc: 0.9797\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0622 - acc: 0.9804\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0608 - acc: 0.9816\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0575 - acc: 0.9821\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0590 - acc: 0.9818\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0564 - acc: 0.9819\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0535 - acc: 0.9833\n",
      "Test loss: 0.019625138468737716 / Test accuracy: 0.9932\n"
     ]
    }
   ],
   "source": [
    "# specify the maximum rotation_range angle\n",
    "rotation_range_val = 30\n",
    "\n",
    "# specify the width and height shift arguments\n",
    "width_shift_val = 0.1\n",
    "height_shift_val = 0.1\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(rotation_range=rotation_range_val, width_shift_range=width_shift_val, height_shift_range=height_shift_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(input_train.reshape(input_train.shape[0], 28, 28, 1))\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "model.fit(datagen.flow(input_train, target_train, batch_size=batch_size),\n",
    "          epochs=no_epochs,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split)\n",
    "\n",
    "# Generate generalization metrics\n",
    "score = model.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate + W&H Shift + Shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 0.7904 - acc: 0.7416\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2973 - acc: 0.9072\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2012 - acc: 0.9372\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1623 - acc: 0.9504\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1361 - acc: 0.9579\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1227 - acc: 0.9617\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1094 - acc: 0.9658\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1029 - acc: 0.9673\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0951 - acc: 0.9695\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0919 - acc: 0.9717\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0834 - acc: 0.9744\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0829 - acc: 0.9743\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0771 - acc: 0.9759\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0758 - acc: 0.9765\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0773 - acc: 0.9752\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0716 - acc: 0.9775\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0688 - acc: 0.9789\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0696 - acc: 0.9788\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0646 - acc: 0.9797\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0628 - acc: 0.9799\n",
      "Test loss: 0.020878435186343268 / Test accuracy: 0.9932\n"
     ]
    }
   ],
   "source": [
    "# specify the maximum rotation_range angle\n",
    "rotation_range_val = 30\n",
    "\n",
    "# specify the shear argument\n",
    "shear_range_val = 25\n",
    "\n",
    "# specify the width and height shift arguments\n",
    "width_shift_val = 0.1\n",
    "height_shift_val = 0.1\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(rotation_range=rotation_range_val, width_shift_range=width_shift_val, height_shift_range=height_shift_val, shear_range=shear_range_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(input_train.reshape(input_train.shape[0], 28, 28, 1))\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "model.fit(datagen.flow(input_train, target_train, batch_size=batch_size),\n",
    "          epochs=no_epochs,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split)\n",
    "\n",
    "# Generate generalization metrics\n",
    "score = model.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate + W&H Shift + Shear + Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.2361 - acc: 0.5862\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.6992 - acc: 0.7712\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.5854 - acc: 0.8105\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.5183 - acc: 0.8307\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.4779 - acc: 0.8444\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 10s 44ms/step - loss: 0.4443 - acc: 0.8555\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 9s 40ms/step - loss: 0.4179 - acc: 0.8643\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.4031 - acc: 0.8679\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.3836 - acc: 0.8762\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.3632 - acc: 0.8821\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.3555 - acc: 0.8840\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.3387 - acc: 0.8899\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.3325 - acc: 0.8907\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.3247 - acc: 0.8941\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.3125 - acc: 0.8983\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.3114 - acc: 0.8983\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.3047 - acc: 0.9010\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.2967 - acc: 0.9043\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.2891 - acc: 0.9046\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.2916 - acc: 0.9045\n",
      "Test loss: 3.303792065048218 / Test accuracy: 0.3509\n"
     ]
    }
   ],
   "source": [
    "# specify the maximum rotation_range angle\n",
    "rotation_range_val = 30\n",
    "\n",
    "# specify the shear argument\n",
    "shear_range_val = 25\n",
    "\n",
    "# specify the width and height shift arguments\n",
    "width_shift_val = 0.1\n",
    "height_shift_val = 0.1\n",
    "\n",
    "# specify the zoom argument\n",
    "zoom_range_val=[2.5,3.5]\n",
    "\n",
    "# create the class object\n",
    "datagen = ImageDataGenerator(rotation_range=rotation_range_val, width_shift_range=width_shift_val, height_shift_range=height_shift_val, shear_range=shear_range_val, zoom_range=zoom_range_val)\n",
    "\n",
    "# fit the generator\n",
    "datagen.fit(input_train.reshape(input_train.shape[0], 28, 28, 1))\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "model.fit(datagen.flow(input_train, target_train, batch_size=batch_size),\n",
    "          epochs=no_epochs,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split)\n",
    "\n",
    "# Generate generalization metrics\n",
    "score = model.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
